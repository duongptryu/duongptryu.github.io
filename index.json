[{"categories":["Golang common mistakes"],"contents":"Như các bạn đã biết thì map là một data type được dựng sẵn trong Golang và nó là một tập hợp các cặp key/value. Nghe thì thấy khá đơn giản nhỉ, khi cần thì add record vào map, còn không cần nữa thì xóa đi. Ủa, đơn giản như vậy mà lại còn được buildin nữa thì sao lại dẫn đến leak memory được, đây là mind set của mình khi mới dùng Go đấy Không dài dòng nữa, mình sẽ đưa ví dụ luôn.\n1. Tình huống package main import ( \u0026#34;runtime\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { // Init n := 1_000_000 m := make(map[int][128]byte) printAlloc() // Add elements for i := 0; i \u0026lt; n; i++ { m[i] = randBytes() } printAlloc() // Remove elements for i := 0; i \u0026lt; n; i++ { delete(m, i) } // End runtime.GC() printAlloc() runtime.KeepAlive(m) } func randBytes() [128]byte { return [128]byte{} } func printAlloc() { var m runtime.MemStats runtime.ReadMemStats(\u0026amp;m) fmt.Printf(\u0026#34;%d MB\\n\u0026#34;, m.Alloc/1024/1024) } Đầu tiên chúng ta sẽ cấp phát memory, khởi tạo empty map m Tiếp theo đó loop 1 triệu lần để gắn elelemt cho m Cuối cùng là remove tất cả elements trong m và chạy GC Sau mỗi bước trên, chúng ta sẽ log size của heap memory bằng runtime.MemStats (MemStats records statistics about the memory allocator). Dòng cuối cùng runtime.KeepAlive(m) để giữ lại reference tới map m không bị thu gom bởi GC. Oke, chạy chương trình nào, cùng dự đoán nhé!!\nWoww, kết quả này có giống như dự đoán của các bạn không?\nSau khi cấp phát memory cho map m, heap size là nhỏ nhất - 0 MB. Sau đó heap size tăng nhanh chóng khi add 1 triệu element vào map m. Cuối cùng, mặc dù GC đã thu gom hết các element bị xóa khỏi map, nhưng heap size vẫn là 293 MB. Heap memory size đã giảm nhưng không như chúng ta mong muốn là 0 MB, right? Vậy đâu là nguyên do?.\n2. Nguyên nhân là do đâu? Trước khi tìm ra nguyên do, chúng ta cần phải biết cách map hoạt động trong golang.\nVề cơ bản, Map trong Go là 1 con trỏ đến runtime.hmap, struct hmap này chứa rất nhiều field, trong đó có B field là thể hiện số lượng bucket hiện có trong map. Mỗi bucket này lại là pointer tới array (mỗi array chỉ có 8 phần tử, khi hết thì tạo thêm array mới và link với array trước) chứa các element của map. Nên khi chúng ta thêm element vào map, thì nghĩa là chúng ta đang thêm element vào bucket. Tương tự như lúc xóa cũng vậy. Mình sẽ để link ở đây cho bạn nào muốn tìm hiểu kỹ hơn về phần này: https://dave.cheney.net/2018/05/29/how-the-go-runtime-implements-maps-efficiently-without-generics\nNhưng có một điều lưu ý ở đây là khi thêm elemenet vào map, số lượng bucket sẽ được cấp phát và tăng lên, element được thêm vào bucket, nhưng khi tiến hành xóa element trong map, thì chúng ta chỉ xóa element trong bucket đấy thôi chứ sẽ không xóa số lượng bucket được cấp phát trước đó.\nNhư trong cuốn sách 100 Mistakes In Golang ở page 88, tác giả đưa ra con số bucket là 262,144 buckets khi thêm 1 triệu element vào, và khi xóa đi thì số lượng bucket vẫn là 262,144.\n=\u0026gt; Kết luận: Số lượng bucket trong map chỉ tăng lên chứ không giảm đi. Và đây chính là nguyên nhân dẫn đến số lượng heap size giảm không đúng theo expected của chúng ta. Vì GC chỉ thu gom những element đã được xóa trong bucket chứ không tác động lên map.\n3. Đây có thực sự là vấn đề? Theo quan điểm của mình thì việc các buckets này không bị xóa đi khi element bị xóa cũng chưa hẳn là xấu. Tốt hay xấu thì cũng phải tùy từng tình huống.\nNếu map của các chúng ta chứa element mà không cần CUD thì tất nhiên sẽ không gặp vấn đề này. Còn nếu map chứa element thường xuyên phải insert và delete thì tất nhiên sẽ gặp vấn đề này. Nhưng trong tình huống này cũng có cái tốt và cái xấu. Khi chúng ta xóa element đi rồi lại thêm element mới vào thường xuyên, thì các bucket trong map vẫn giữ nguyên, hệ thống sẽ không cần phải cấp phát lại bucket nữa, qua đó sẽ tăng performance xíu xíu cho hệ thống :v. Còn mặt xấu thì các bạn thấy rồi đấy, memory sẽ không giảm đúng theo expected của chúng ta, dev mà không có kinh nghiệm về mảng này là mò hoài không ra lý do tại sao Mem cứ tăng mà giảm xíu xíu, xong rồi lại bị sếp đè đầu hỏi =)))\nTrong thực tế thì case này rất dễ xảy ra, ví dụ khi hệ thống của bạn sử dụng map để lưu data cache của user, vào các ngày khuyến mại lớn như 1/1, có hàng triệu triệu người dùng vào website mua sắm. Nhưng sau đó vài ngày, bạn vẫn thấy lượng Mem của server ở mức cao mà không hề giảm, thế là ông sếp lại đè đầu bạn ra để trừ lương :v.\nCách đây vài tháng, mình cũng từng gặp case như vậy, mình làm freelance cho một công ty về mảng live stream, nội dung giải trí, truyền hình trực tuyến. Họ dùng cache local để lưu lại data của người dùng và toàn bộ thông tin về danh mục xem của mỗi người dùng (cái data này to vcl lun). Xong mỗi lần chạy load testing cái là memory của server nó tăng như tên lửa, không giảm tý nào luôn. Sếp mình lúc đấy chắc cũng bế tắc, thế là đá cái task đấy cho mình, bảo mình nghiên cứu xem sao mem k giảm =)). Mình lúc đấy là thằng sv mới ra truường thì có biết gì đâu. Ngồi nghiên cứu cả tháng trời mà không có báo cáo gì. Kết quả là gì thì các bạn cũng đoán được rồi đấy =)))\n4. Giải pháp Giải pháp đơn giản nhất là reset service rồi, nhưng chúng ta đâu thể tự reset đúng không, lại phải ới ông devops bảo \u0026ldquo;Alo a ơi, a reset con service X hộ e với\u0026rdquo;. Gặp ông devops dễ thì không sao, chứ gặp ông khó tính thì dời ơi đất hỡi lắm. Mà reset một lần thì có thể không sao, chứ reset nhiều lần trong 1 tháng thì mình nghĩ chắc cũng sắp nghỉ việc rồi đấy =))\nGiải pháp tiếp theo là tạo lại map đó. Giả sử chúng ta chạy 1 goroutine, cứ mỗi 1 tiếng thì nó lại copy tất cả element trong map cũ và thêm vào map mới, xong replace map cũ là xong. Nhưng cái này cũng có nhược điểm, sau khi copy tất cả elements sang map mới thì mem của chúng ta vẫn tồn tại map cũ cho đến khi GC lần tiếp theo thu gom.\nMột giải pháp khác là chúng ta lưu trữ con trỏ trỏ đến data, chứ không lưu trực tiếp data trong map. Nó không xử lý được vấn đề về số lượng bucket không giảm, nhưng nó sẽ giảm kích thước phải lưu trữ trong bucket.\n5. Summary Chúng ta cần phải chú ý khi dụng map trong golang nếu không muốn những tháng ngày debug không lối thoát :v. Các bạn nên cân nhắc xem tình huống này có sử dụng map được không, và nếu sử dụng thì sẽ gặp vấn đề gì khi số lượng element trong map phình to. Và cuối cùng là phải ghi nhớ: \u0026ldquo;Go map can only grow in size, there is not automated strategy to shrink it.\u0026rdquo;\nP/s: Đây là lần đầu tiên mình viết bài chia sẻ kiến thức, và kinh nghiệm của mình vẫn còn khá ít, chủ yếu là trên sách vở, sẽ không thể tránh được những sai lầm. Nhưng mình luôn luôn có mong muốn được chia sẻ những kiến thức mà mình biết đến với mọi người, đặc biệt là gopher :v. Nên mình rất mong muốn có những phản hồi đóng góp chia sẻ của các độc giả để các bài sau mình có thêm động lực để viết tốt hơn. Thanks for everyone !!!!\n6. References https://dave.cheney.net/2018/05/29/how-the-go-runtime-implements-maps-efficiently-without-generics\nHarsanyi, T. (2022) 100 go mistakes. Shelter Island: Manning Publications.\n","permalink":"https://duongptryu.github.io/blog/golang-map-leak-memory/","tags":["Golang","Memory Leak","Map","vietnamese"],"title":"Memory leak do sử dụng map sai cách trong Golang?"},{"categories":["Golang common mistakes"],"contents":"Chào mừng các bạn đã quay trở lại với series những common mistakes trong Golang. Trong bài này, chúng ta sẽ tìm hiểu về nguyên nhân gây ra memory leak liên quan đến slice, array trong Go. Không giống như C/C++, Go có GC, vì thế chúng ta không cần quan tâm đến memory allocation hay release. Tuy nhiên, chính vì có sự giúp đỡ của GC mà chúng ta cần hiểu cách GC hoạt động để phòng tránh những trường hợp vô ý gây ra memory leak. Và trong bài này, chúng ta sẽ tìm hiểu về leaking memory do sử dụng slicing slice.\n1 Scenario Giả sử chúng ta có một service consumer, service này sẽ nhận data dưới dạng slice, 5 vị trí đầu của slice là type của data. Service sẽ lấy 5 phần tử đầu tiên của data để thực hiện một số chức năng.\nDưới đây sễ là ví dụ đơn giản.\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;runtime\u0026#34; ) func main() { // Start printAlloc() dataReceived := make([]byte, 1024*1024) // Giả sử mình nhận được data slice có dung lượng là 1 MB printAlloc() typeData := getTypeOfData(dataReceived) // Lấy 5 phần tử đầu tiên của data // Do something with typeData // storeTypeDataInCache(typeData) runtime.GC() // Chạy GC thu gom runtime.KeepAlive(typeData) // Giữ lại typeData variable printAlloc() // End } func getTypeOfData(data []byte) []byte { return data[:5] // thực hiện slicing slice } func printAlloc() { var m runtime.MemStats runtime.ReadMemStats(\u0026amp;m) fmt.Printf(\u0026#34;%d MB\\n\u0026#34;, m.Alloc/1024/1024) } Ở đây để đơn giản thì mình sẽ khởi tạo dataReceived với dung lượng 1MB (Các bạn cứ hình dung là chúng ta nhận được 1MB data từ request hoặc service khác nhé :v). Sau khi nhận được dataReceived, mình sẽ tiến hành lấy 5 phần tử đầu tiên của slice bằng cách slicing như code trên. Cuối cùng mình sẽ dun runtime.KeepAlive để giữ typeData không bị thu gom bởi GC, để minh họa cho việc mình sẽ lưu typeData vào memory cache của chương trình. Sau mỗi bước mình sẽ print memory stack của process để xem hiện tại process tiêu tốn bao nhiêu dung lượng. Code không có vấn đề gì và khá dễ hiểu nhỉ. Trước khi chạy chương trình thì các bạn hay đoán xem dung lượng memory stack khi start và end là bao nhiêu nhé. Theo lý thuyết thì dataReceived có khoảng 1 triệu phần tử thì chiếm 1MB memory, typeData có 5 phần từ thì chiếm khoảng 5 byte he. Chạy chương trình xem có đúng vậy không nào.\nÂu shit, memory stack lúc nhận data và sau khi GC thu gom là giống nhau. Vậy không phải là 5 byte như chúng ta dự đoán. Vậy có nghĩa là typeData đang giữ dung lượng là 1MB? Thế này nếu service nhận 1 nghìn data giống như này, thì memory nó cần tận 1GB lận. Đến đây có thể các bạn sẽ nghĩ rằng một là code có vấn đề, hai là giả định của chúng ta ở trên là sai. Vậy chúng ta cùng tìm hiểu nguyên nhân là tại sao.\n2. How slice work Trước tiên, chúng ta cần hiểu cách slice hoạt động.\nSlice trong Golang là fat pointer. Các bạn có thể đọc ở bài viết này để hiểu hơn về fat pointer. Cấu trúc của slice bao gồm:\ntype SliceHeader struct { Data uintptr // đỉa chỉ trong bộ nhớ của con trỏ trỏ tới underlying array của slice. Len int // độ dài của slice. Cap int // kích thước tối đa mà vùng nhớ trỏ tới slice được cấp phát. } Về cơ bản, các bạn có thể hiểu là khi chúng ta có một slice thì nghĩa là chúng ta đang có một pointer trỏ tới underlying array của slice đấy.\n3. Reason Sau khi hiểu cách slice hoạt động, chúng ta cùng quay lại để visualize vấn đề ở trên nào.\ndataReceived khi init, các bạn có thể hình dung nó như này. 1 array gồm 1 triệu elements sẽ được cấp phát ở memory stack, và dataReceived sẽ trỏ pointer tới đó.\nSau đó, chúng ta tạo thêm 1 slice typeData từ slice dataReceived bằng phương pháp slicing. Khi sử dụng phương pháp slicing thì thay vì tạo ra một underlying array mới thì Go sẽ trỏ pointer vào underlying array có sẵn đó như hình dưới đây. Khi đó, typeData của chúng ta mặc dù chỉ có 5 phần tử nhưng capacity của nó là 1M phần tử.\nCuối cùng khi process kết thúc.\nChúng ta keepAlive typeData, còn dataReceived sẽ được thu gom bởi GC. Nhưng vì underlying array của dataReceived vẫn đang được typeData trỏ tới, nên GC sẽ không thu gom nó, mà nó vẫn sẽ tồn tại trong memory cho đến khi nào mà không còn slice nào trỏ đến nó. Và đây chính là lý do tại sao sau khi process kết thúc mà chúng vẫn thấy có 1MB tồn tại trong memory. Vậy giải pháp của vấn đề này là gì?\n4. Solution Ở trên 2 slice cùng trỏ vào một underlying array, vậy nếu giờ chúng ta tách 2 slice đó thành 2 underlying array riêng biệt thì sẽ giải quyết được vấn đề. Khi đó GC sẽ thu gom hoàn toàn dataReceived và chỉ giữ lại typeData.\nĐể triển khai giải pháp này, chúng ta sẽ dùng phương pháp copy slice thay vì slicing slice như trước.\nBởi vì chúng ta dùng phương pháp copy, typeData sẽ có độ dài là 5 và capacity là 5 thay vì 1M, lưu trữ 5 bytes trong memory thay vì 1MB như trước đó.\nSửa lại function getTypeOfData nào.\nfunc getTypeOfData(data []byte) []byte { dataType := make([]byte, 5) copy(dataType, data) return dataType } Chạy lại và xem kết quả.\nKết sau khi chúng ta update code là 0 MB. Đây là do function printAlloc() của mình đã chia dung lượng bytes cho 1024*1024 để convert dung lượng sang MB nên nó sẽ làm tròn số float. Mình sẽ sửa lại hàm lại 1 chút để cho nó print dung lượng bytes.\nfunc printAlloc() { var m runtime.MemStats runtime.ReadMemStats(\u0026amp;m) fmt.Printf(\u0026#34;%d bytes - %d MB \\n\u0026#34;, m.Alloc, m.Alloc/1024/1024) } Chạy lại chúng ta sẽ nhận được kết quả.\nKhi process khởi tạo, memory là 104800 bytes, và sau khi process kết thúc, memory là 110408 bytes, chênh lệch khoảng 5608 bytes :D. Và ở trong 5608 bytes này sẽ tồn tại 5 bytes của chúng ta lưu trữ typeData. Bởi vì khi chạy chương trình sẽ có thêm những phần được khởi tạo và cấp phát memory ở bên dưới mà chúng ta không nhìn thấy nên con số memory sẽ có chút chênh lệch. Nhưng thật vui khi thấy dung lượng memory không còn là 1MB như trước đúng không nào :v.\n5. Recap Tóm lại, hãy nhớ rằng khi slicing một slice hoặc array có dung lượng lớn có thể dẫn đến leaking memory. Underlying array sẽ không được GC thu gom khi vẫn có pointer trỏ tới. Và chúng ta có thể giữ lại underlying array rất lớn trong memory trong khi chỉ sử dụng vài element của underlying array đó. Và copy slice là giải pháp để phòng tránh trường hợp này.\n6. References Harsanyi, T. (2022) 100 go mistakes. Shelter Island: Manning Publications.\n","permalink":"https://duongptryu.github.io/blog/golang-slicing-leak-memory/","tags":["Golang","Memory Leak","Slice","vietnamese","Array"],"title":"Sai lầm khi sử dụng slicing slice trong Golang"}]